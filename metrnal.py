# -*- coding: utf-8 -*-
"""metrnal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fgzT8DoNWNQydzeFm9Kz0zfcaKtcYc2w
"""

import pandas as pd
data=pd.read_csv('Maternal Health Risk Data Set.csv')
print(data)

print(data.isnull().sum())

print(data.dtypes)

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
def FunLabelEncoder(df):
  for c in df.columns:
    if df.dtypes[c]==object:
      le.fit(df[c].astype(str))
      df[c]=le.transform(df[c].astype(str))
  return df
  data=FunLabelEncoder(data)
data.iloc[:,:]

x=data.iloc[:,:-1].values
print(data)

y=data.iloc[:,-1].values
print(y)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

print(x_train)

print(x_test)

print(y_train)

print(y_test)

from sklearn.tree import DecisionTreeClassifier
classifier=DecisionTreeClassifier()
classifier.fit(x_train,y_train)

y_pred=classifier.predict(x_test)
print(y_pred)

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

import pandas as pd
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('Maternal Health Risk Data Set.csv')

# Preprocess the data
X = data.drop('RiskLevel', axis=1)
y = data['RiskLevel']

# Encode the target variable
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Decision Tree Classifier model
classifier = DecisionTreeClassifier(max_depth=3, random_state=42)

# Fit the model
classifier.fit(X_train, y_train)

# Make predictions
y_pred = classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Plot the Decision Tree
plt.figure(figsize=(40, 20))
plot_tree(classifier, filled=True, feature_names=X.columns, class_names=list(label_encoder.classes_), fontsize=12)
plt.title('Decision Tree Classifier')
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
file_path = "Maternal Health Risk Data Set.csv"
df = pd.read_csv(file_path)

# Encode the categorical target variable
label_encoder = LabelEncoder()
df['RiskLevel'] = label_encoder.fit_transform(df['RiskLevel'])

# Define features and target
X = df.drop(columns=['RiskLevel'])  # Features
y = df['RiskLevel']  # Target

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Logistic Regression model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_report(y_test, y_pred))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
file_path = "Maternal Health Risk Data Set.csv"
df = pd.read_csv(file_path)

# Encode the categorical target variable
label_encoder = LabelEncoder()
df['RiskLevel'] = label_encoder.fit_transform(df['RiskLevel'])

# Define features and target
X = df.drop(columns=['RiskLevel'])  # Features
y = df['RiskLevel']  # Target

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Gradient Boosting model
model = GradientBoostingClassifier(random_state=42)  # You can adjust hyperparameters here
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_report(y_test, y_pred))

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score


# ... (Your existing data loading and preprocessing code) ...

# Assuming you have X_train, X_test, y_train, y_test ready

# Train and evaluate each model
# 1. Decision Tree
dt_classifier = DecisionTreeClassifier()
dt_classifier.fit(X_train, y_train)
y_pred_dt = dt_classifier.predict(X_test)
Accuracy_DT = accuracy_score(y_test, y_pred_dt)

# 2. Logistic Regression
lr_classifier = LogisticRegression(max_iter=1000)  # Increase max_iter if needed
lr_classifier.fit(X_train, y_train)
y_pred_lr = lr_classifier.predict(X_test)
Accuracy_LR = accuracy_score(y_test, y_pred_lr)

# 3. Gradient Boosting
gb_classifier = GradientBoostingClassifier(random_state=42)
gb_classifier.fit(X_train, y_train)
y_pred_gb = gb_classifier.predict(X_test)
Accuracy_GB = accuracy_score(y_test, y_pred_gb)

# Create the accuracy series and plot
model_accuracy = pd.Series(data=[Accuracy_DT, Accuracy_LR, Accuracy_GB],
                            index=['Decision Tree', 'Logistic Regression', 'Gradient Boosting'])

fig = plt.figure(figsize=(8, 6))  # Adjust figure size if needed
model_accuracy.sort_values().plot.barh(color=['skyblue', 'lightgreen', 'salmon']) # Customize colors
plt.title('Comparison of Model Accuracies')
plt.xlabel('Accuracy')
plt.ylabel('Model')
plt.tight_layout()  # Adjust layout for better spacing
plt.show()